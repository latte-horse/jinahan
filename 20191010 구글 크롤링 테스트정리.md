# 20191010 구글 크롤링 테스트



> 구글 크롤링 테스트를 한 결과 70의 성공이다. 왜냐하면 크롤링 자체는 성공을 했으나, 실행을 할 때 브라우저를 기반으로 해서 실행이된다. 그래서 리눅스에서 하둡,쁘띠?(아직 완전히 모르겠다.)를 할 때 진행이 안된다고 한다. ㅠ 하지만 누군가 구글 크롤링을 할 수 있기에 정리를 해서 올린다.
>
> 구글 크롤링은 진행 중에 상당히 어려웠다. 왜냐하면 구글 자체내에서 14년도에 검색 API를 폐쇠를 하고 유로화 정책을 시작했다. (1000건에 5$였나?) 그래서 자체적으로 구글 크롤링을 제작하였다. 
>
> 만드는 과정은 어려웠지만, 다 만들고 나니 참 나다운 코딩이 나왔다. 직관적이다. 딱보면 음... 이런 거군 할 수 있는 초보자의 작품. 혹시나 더 나은 코드가 있다면 꼭 알려주면 좋겠다. 



```python
from selenium import webdriver
import bs4 
import requests
import pandas
import parser
from bs4 import BeautifulSoup


#준비물로 selenium, bs4,BeautifulSoup,pandas,parser 많은 것들을 임포트 시켜야 한다.

#만약 이글을 읽고 있는 사람이 매우 초보인데 시도한다면 위의 인포트는 pip install XXXX 로 CMD 창에서 하면된다. 
그런데도 안되면 구글에서 'pip 안됨' 이런 식으로검색을 한다면 꽤나 여러게 나온다. 한번 여기저기 살펴본다면 도움이 될 것 같다.  

#def gglist(Key_Word):
#모듈화를 시도하려고 했던 주석

browser = webdriver.Firefox(executable_path='C:/Users/student/Documents/jinahan/googlecroll/geckodriver.exe')

# geckodriver.exe firebox 전용 웹드라이브이다. 이것 말고도 크롬도 있는데 훨씬더 대중적인것 같다. 왜냐하면 검색량자체가 훨씬많다. 
#나는 시작을 저녀석으로 해서 끝까지 하게 되었다.

RealPage = ["https://www.google.com/search?q="+"이다희"+"&sxsrf=ACYBGNSRzU3ufdsJK1P8V79WyrsOnA4NIg:1570437429290&source=lnms&tbm=nws",
            "https://www.google.com/search?q="+"이다희"+"&tbm=nws&ei=Ez6cXcfoJ62ymAX-goLACw&start=10&sa=N",
            "https://www.google.com/search?q="+"이다희"+"&tbm=nws&sxsrf=ACYBGNRHe5rC4V-P1kvtVm1bO_pnY56IrA:1570522095629&ei=70OcXcaGJqyymAW73L8Y&start=20"]

#시작부터 참... 분명히 더 명료하게 짤 수 있을 것 같은 코드인데 아직은 능력이 부족한 것 같다. 
#이 부분은 1페이지,2페이지,3페이지 넘기기 위한 리스트다. 순서는 차례대로 이다. 
#구글의 경우에는 검색을 할 때마다 계속해서 달라지고, 패턴을 읽기가 어렵다.
#네이버, 다음 같은 경우에는 &을 기점으로 해서 잘 설펴보면 패턴이 존재하니 참고를 하자.
#+ + 사이에 키워드를 넣고 페이지를 넘겨주는 파트라고 생각하면 된다.

for page in RealPage:
    Next_page = browser.get(page)
    hrefs = []
    titles = []

    for i in range(0,10):
        results = browser.find_elements_by_css_selector('div.g')
        link = results[i].find_element_by_tag_name("a.lLrAF")
        hrefs.append(link.get_attribute("href"))
        titles.append(link.text)

for whole in range(0,3):
    for list_up in range(0,10):
        print(hrefs[list_up])
        print(titles[list_up])


#for문을 이용해서 쭉 진행을 했다. #https://seleniumhq.github.io/selenium/docs/api/py/webdriver_remote/selenium.webdriver.remote.webelement.html 
#위의 사이트는 셀레니움의 메소드를 배울수 있다. 그외에도 꽤나 쓸만한 정보들이 많으니 참고 하면 좋을 듯하다. 

#간단히 요약을 하면 이렇다. 총 3개의 페이지에 있는 10개의 url을 읽어온다. 
#중간에 있는 results 와  link,href 등은 각 기사의 url과 제목을 가지고 오는 코드의 변수명이다. 
#변수들의 클래스는 이름 같아서 나름 가지고 오는 것이 수월했다. 

#마지막 for문 은 위에서 for문으로 list를 만들었기 때문에 이중 리스트문으로 해야한다고 한다. 
#나는 출력이 url 한줄 제목 한줄 씩 나와서 인덱스 형식으로 30개를 불러오려 했다. 
#하지만 index range 에러가 계혹해서 떠서 선생님께 물어보았다. 그래서 위에 언급한 답을 얻었다.

browser.close()   

<결과>
https://news.mt.co.kr/mtview.php?no=2019092310550365109
이다희, 블랙 시스루 의상…하이 포니테일 '눈길'
https://news.mt.co.kr/mtview.php?no=2019092614195353045
[ 화보]이다희 '화보 속 한장면처럼!'
https://www.wikitree.co.kr/main/news_view.php?id=467086
“롱코트가 이다희를 입었네” 백화점에 뜬 이다희 (사진)
http://www.shinmoongo.net/130749
이다희, 레오파드 코트로 완성한 시크한 가을패션
http://moneys.mt.co.kr/news/mwView.php?no=2019092614208074048&code=w1202&MRN
[머니S포토] 이다희 '반박불가 예쁨'
https://www.seoul.co.kr/news/newsView.php?id=20190926801001
[포토] 배우 이다희, '우아한 가을 여인'
http://www.sisafocus.co.kr/news/articleView.html?idxno=222954
[포토] 이다희, 꽃보다 아름다운 미소
http://www.asiatoday.co.kr/view.php?ke
    .
    .
    .
    .
```



